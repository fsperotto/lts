{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities dataset successfully reformatted.\n",
      "Elements dataset successfully reformatted\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "from boltons.iterutils import windowed\n",
    "\n",
    "def _merge_elements(elements_dir):\n",
    "    \"\"\" For elements file, merge titles with content \"\"\"\n",
    "    # Read titles\n",
    "    with open(elements_dir+'wikielements.segmenttitles', 'r') as f:\n",
    "        titles = f.readlines()\n",
    "    titles = [title.strip() + '\\x01' for title in titles]\n",
    "\n",
    "    # Read line content\n",
    "    with open(elements_dir+'wikielements.text', 'r') as f:\n",
    "        outputs = [''.join([title, line]) \n",
    "                   for title, line in zip(titles, f.readlines())]\n",
    "\n",
    "    # Merge titles, content together in a new output file\n",
    "    with open(elements_dir+'elements.text', 'w') as f:\n",
    "        for line in outputs:\n",
    "            f.write(line)\n",
    "\n",
    "def _read_original(filename):\n",
    "    \"\"\" Read original Chen file lines, separate title and text \"\"\"\n",
    "    unaligned = []\n",
    "    # Read in the original file\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "\n",
    "            # Split line into raw version of (title, text)\n",
    "            split = line.strip().split('\\x01')\n",
    "\n",
    "            # Remove numbers, commas from title\n",
    "            title = re.sub('[,0-9]+', '', split[0])\n",
    "            text = split[1]\n",
    "            \n",
    "            yield title, text\n",
    "\n",
    "def _align(unaligned):\n",
    "    \"\"\" Group the unaligned Chen text by their titles.  \"\"\"\n",
    "    aligned, group, last_title = [], [], 'TOP-LEVEL SEGMENT'\n",
    "\n",
    "    for title, line in unaligned:\n",
    "\n",
    "        if title != last_title:\n",
    "            aligned.append((last_title, group))\n",
    "            group = [line]\n",
    "        else:\n",
    "            group.append(line + '.')\n",
    "\n",
    "        last_title = title\n",
    "    \n",
    "    # Edge case\n",
    "    aligned.append((last_title, group))\n",
    "    return aligned\n",
    "\n",
    "def _doc(aligned):\n",
    "    \"\"\" Break aligned Chen text into their individual documents \"\"\"\n",
    "    indexes = _indexes(aligned)\n",
    "    documents = [aligned[start:stop] for start, stop in indexes]\n",
    "    return documents\n",
    "                \n",
    "def _indexes(aligned):\n",
    "    \"\"\" Return tuples of (start, stop) indexes for documents \"\"\"\n",
    "    return windowed([i for i, (title, _) in enumerate(aligned) \n",
    "                     if title == 'TOP-LEVEL SEGMENT'] + [len(aligned)], 2)\n",
    "\n",
    "def _write(documents, outdir):\n",
    "    \"\"\" Write out documents to outdir \"\"\"\n",
    "    # If outdir doesn't exist, make it\n",
    "    try:\n",
    "        os.makedirs(outdir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # Write a new file for each document\n",
    "    for idx, doc in enumerate(documents):\n",
    "        filename = str(idx+1) + '.txt'\n",
    "        with open(outdir + filename, 'w') as f:\n",
    "            \n",
    "            # Write out each subsection, delimited by '========'\n",
    "            for idx2, group in enumerate(doc):\n",
    "                title, text = group\n",
    "                f.write('========,' + str(idx2+1) + ',' + title + '.' + '\\n')\n",
    "                for line in text:\n",
    "                    f.write(line + '\\n')\n",
    "                    \n",
    "def reformat(files):\n",
    "    \"\"\" Put it all together to convert wikicites to proper format.\n",
    "    Input: list of tuples (source file, out directory)\n",
    "    Output: reformatted data in \n",
    "    \"\"\" \n",
    "    \n",
    "    for src, out in files:\n",
    "        unaligned = _read_original(src)\n",
    "        aligned = _align(unaligned)\n",
    "        documents = _doc(aligned)\n",
    "        _write(documents, outdir=out)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    cities_files = [ ('../data/wikicities-english/training/wikicities.text', \n",
    "                      '../data/cities/train/'),\n",
    "                    ('../data/wikicities-english/test/wikicities.text', \n",
    "                      '../data/cities/test/')]\n",
    "    \n",
    "    # Merge element titles with their content\n",
    "    _merge_elements(elements_dir='../data/wikielements/')\n",
    "    \n",
    "    elements_files = [('../data/wikielements/elements.text',\n",
    "                      '../data/elements/test/')]\n",
    "    \n",
    "    reformat(cities_files)\n",
    "    print('Cities dataset successfully reformatted.')\n",
    "    reformat(elements_files)\n",
    "    print('Elements dataset successfully reformatted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
