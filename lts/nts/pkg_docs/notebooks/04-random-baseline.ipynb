{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_pk : 0.4131459532678631899762952934\n",
      "w_wd : 0.4816821499668214996682149967\n",
      "w_ss : 0.9714017437961099932930918843\n",
      "w_bs : 0.07309479940669521003452196326\n",
      "w_precision : 0.07309479940669521003452196326\n",
      "w_recall : 0.07309479940669521003452196326\n",
      "w_f1 : 0.1348172967415940317544673848\n",
      "s_pk : 0.4916515609264853977844914401\n",
      "s_wd : 0.5431224899598393574297188755\n",
      "s_ss : 0.815130784708249496981891348\n",
      "s_bs : 0.1359400582917160605928453471\n",
      "s_precision : 0.1444640881120230556388977116\n",
      "s_recall : 0.1444640881120230556388977116\n",
      "s_f1 : 0.2522675359184043844863023784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import random\n",
    "from src.loader import *\n",
    "from src.metrics import Metrics, avg_dicts\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Random:\n",
    "    \"\"\" Random baseline: probability of 1/(Avg seg length) \n",
    "    that a sentence ends a seg \n",
    "    \"\"\"\n",
    "    \n",
    "    evalu = Metrics()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        return self.validate(*args)\n",
    "        \n",
    "    def validate(self, dirname):\n",
    "        \"\"\" Sample N floats in range [0,1]. If a float is less than the inverse\n",
    "        of the average segment length, then say that is a predicted segmentation \"\"\"\n",
    "        if 'probability' not in self.__dict__:\n",
    "            self.probability, self.labels, self.counts = self.parametrize(dirname)\n",
    "        \n",
    "        samples = [random.random() for _ in self.labels]\n",
    "        preds = [1 if s <= self.probability else 0 \n",
    "                 for s in samples]\n",
    "        batch = PseudoBatch(self.counts, self.labels)\n",
    "        metrics_dict = self.evalu(batch, preds)\n",
    "        \n",
    "        return batch, preds, metrics_dict\n",
    "    \n",
    "    def parametrize(self, dirname):\n",
    "        \"\"\" Return 1 / average segment as random probability pred, test_dir's labels \"\"\"\n",
    "        counts = flatten([self.parse_files(f) for f in crawl_directory(dirname)])\n",
    "        labels = counts_to_labels(counts)\n",
    "        avg_segs = sum(counts) / len(counts)\n",
    "        probability = 1 / avg_segs\n",
    "        \n",
    "        return probability, labels, counts\n",
    "    \n",
    "    def parse_files(self, filename, minlen=1):\n",
    "        \"\"\" Count number of segments in each subsection of a document \"\"\"\n",
    "        counts, subsection = [], ''\n",
    "        with open(filename, encoding='utf-8', errors='strict') as f:\n",
    "\n",
    "            # For each line in the file, skipping initial break\n",
    "            for line in f.readlines()[1:]:\n",
    "\n",
    "                # This '========' indicates a new subsection\n",
    "                if line.startswith('========'):\n",
    "                    counts.append(len(sent_tokenizer.tokenize(subsection.strip())))\n",
    "                    subsection = ''\n",
    "                else:\n",
    "                    subsection += ' ' + line\n",
    "\n",
    "            # Edge case of last subsection needs to be appended\n",
    "            counts.append(len(sent_tokenizer.tokenize(subsection.strip())))\n",
    "\n",
    "        return [c for c in counts if c >= minlen]\n",
    "    \n",
    "    def cross_validate(self, *args, trials=100):\n",
    "        \"\"\"  \"\"\"\n",
    "        dictionaries = []\n",
    "        for seed in tqdm(range(trials)):\n",
    "            random.seed(seed)\n",
    "            batch, preds, metrics_dict = self.validate(*args)\n",
    "            dictionaries.append(metrics_dict)\n",
    "        \n",
    "        merged = avg_dicts(dictionaries)\n",
    "        return merged\n",
    "        \n",
    "random_baseline = Random()\n",
    "# _, _, metrics_dict = random_baseline.validate('../data/wiki_50/test')\n",
    "metrics_dict = random_baseline.cross_validate('../data/wiki_50/test', trials=100)\n",
    "for k, v in metrics_dict.items():\n",
    "    print(k, ':', v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
